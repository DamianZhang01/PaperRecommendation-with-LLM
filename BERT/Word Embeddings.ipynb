{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89352281-16b9-4a97-8f30-22226d7f4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from random import randrange\n",
    "# from tqdm.notebook import tqdm_no\n",
    "from IPython.display import display, Markdown\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, BertModel, BertForNextSentencePrediction, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1b967e-4603-4271-8f7c-790e4085b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your corresponding key to download dataset from Kaggle\n",
    "# https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
    "\n",
    "with open('./kaggle.json') as f:\n",
    "    file = json.load(f)\n",
    "\n",
    "os.environ[\"KAGGLE_KEY\"] = file['key']\n",
    "os.environ[\"KAGGLE_USERNAME\"] = 'jeploretizo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d645ae8-9cec-40b1-ae2c-297226f294a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d Cornell-University/arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e854e317-1889-4f27-836b-4905bca05d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip \"arxiv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e096305d-c90a-447e-a728-7c7f2bcbfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "FILE_PATH ='./arxiv-metadata-oai-snapshot.json'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25208d6e-4774-4711-bb9e-aec95dfd2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    with open(FILE_PATH) as f:\n",
    "        for line in f:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d73cb1c-3ffe-4dd2-bf42-2961d06e1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_limit = 2023\n",
    "\n",
    "dataframe = {\n",
    "    'id': [],\n",
    "    'title': [],\n",
    "    'year': [],\n",
    "    'abstract': []\n",
    "\n",
    "}\n",
    "\n",
    "data = get_data()\n",
    "for i, paper in enumerate(data):\n",
    "    paper = json.loads(paper)\n",
    "    try:\n",
    "        date = int(paper['update_date'].split('-')[0])\n",
    "        if date > year_limit:\n",
    "            dataframe['title'].append(paper['title'])\n",
    "            dataframe['year'].append(date)\n",
    "            dataframe['abstract'].append(paper['abstract'])\n",
    "            dataframe['id'].append(paper['id'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f21cfa9-bf0e-4b2c-a097-a267c993f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataframe)\n",
    "\n",
    "# Limit to first 500 for training purposes\n",
    "df = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ba8cbc6-1b12-464d-ae22-f216a2002f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c2d1cc-e406-4b7a-8f81-3d81d39d81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_scores(query_string, reference_list, BATCH_SIZE=16):\n",
    "  similarity_scores = []\n",
    "  paired_texts = [(query_string, reference_row) for reference_row in reference_list]\n",
    "\n",
    "  for i in range(0, len(paired_texts), BATCH_SIZE):\n",
    "      batch = paired_texts[i:i + BATCH_SIZE]\n",
    "      encoded_sequences = tokenizer(\n",
    "          [pair[0] for pair in batch],\n",
    "          [pair[1] for pair in batch],\n",
    "          padding='longest',\n",
    "          truncation='longest_first',\n",
    "          return_tensors='pt',\n",
    "          max_length=MAX_SEQUENCE_LENGTH\n",
    "      ).to(device)\n",
    "\n",
    "      outputs = model(\n",
    "          input_ids=encoded_sequences['input_ids'],\n",
    "          attention_mask=encoded_sequences['attention_mask'],\n",
    "          token_type_ids=encoded_sequences['token_type_ids']\n",
    "      )\n",
    "\n",
    "      probs = F.softmax(outputs.logits, dim=1)\n",
    "      similarity_scores.extend(probs[:, 0].detach().cpu().numpy())\n",
    "\n",
    "  return similarity_scores\n",
    "\n",
    "# Assuming similarity_scores is now a list of similarity scores,\n",
    "# one for each row in your original DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67bd7e9f-facd-4fc3-8359-212a01ba3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"I don't know\"\n",
    "df['similarity_score'] = get_similarity_scores(query_string, df['abstract'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d05b5720-5ce1-4e36-ae28-7883fac90715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aea363ee-96a5-467e-a4f4-fa4f32690acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Are Particles Self-Organized Systems?\n",
      "----\n",
      "ABSTRACT:   Where did elementary particles come from? What mechanisms are responsible for\n",
      "their occurrence and maintenance? Are they compound or truly elementary? Is\n",
      "vacuum primordial soup where elementary particles are born? Are quantum\n",
      "behavior and relativistic phenomena fundamental or emergent? This paper\n",
      "describes a primitive active medium far from thermodynamic equilibrium, which\n",
      "we associate with vacuum and in which a system of particles and fields arises,\n",
      "similar to that described by the standard model. Phenomena usually attributed\n",
      "to quantum or relativistic media emerge during vacuum self-organization. These\n",
      "include discrete spectra of ground states, charges, oscillation periods, and\n",
      "link flavors, spatial phase coherency, virtual states, tunneling, entanglement,\n",
      "time-related uncertainty of states, and coexistent Planck-like and\n",
      "Einstein-like time scales. The form of vacuum self-organization is a coherent\n",
      "time-crystal network. Here, different fields arise as quantum states of the\n",
      "same gravitation-antigravitation field. Particle-like entities emerge as\n",
      "topological defects. The analysis was accompanied by numerical estimates of\n",
      "several physical constants, the values of which had never previously been\n",
      "derived from theory. These results are consistent with the experimental data.\n",
      "\n",
      "----\n",
      "SIMILARIY SCORE: 0.467299\n",
      "====\n",
      "TITLE: The Pointillist principle for variation operators and jump functions\n",
      "----\n",
      "ABSTRACT:   We extend the pointillist principles of Moon and Carrillo--de Guzm\\'an to\n",
      "variational operators and jump functions.\n",
      "\n",
      "----\n",
      "SIMILARIY SCORE: 0.3254448\n",
      "====\n",
      "TITLE: On deformation spaces of quadratic rational maps\n",
      "----\n",
      "ABSTRACT:   We study the group of self-equivalences of a partially postcritically finite\n",
      "branched cover and answer a question of Adam Epstein about contractibility of\n",
      "certain deformation spaces of rational maps.\n",
      "\n",
      "----\n",
      "SIMILARIY SCORE: 0.28733248\n",
      "====\n",
      "TITLE: Axiomatic phylogenetics\n",
      "----\n",
      "ABSTRACT:   We use the language of quivers to formulate a mathematical framework for\n",
      "phylogenetics.\n",
      "\n",
      "----\n",
      "SIMILARIY SCORE: 0.28186598\n",
      "====\n",
      "TITLE: Graph Theory\n",
      "----\n",
      "ABSTRACT:   This is a replacement paper. There are 6 chapters. The first two chapters are\n",
      "introductory. The third chapter is on extremal graph theory. The fourth chapter\n",
      "is about algebra in graph theory. The fifth chapter is focused on algorithms.\n",
      "The third section of the fifth chapter deals with computable time. The sixth\n",
      "chapter has sections on probability and enumeration.\n",
      "\n",
      "----\n",
      "SIMILARIY SCORE: 0.26214185\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    row = df.iloc[i]\n",
    "    print(\"TITLE:\", f\"{row['title']}\")\n",
    "    print('----')\n",
    "    print(\"ABSTRACT:\", row['abstract'])\n",
    "    print('----')\n",
    "    print(\"SIMILARIY SCORE:\", row['similarity_score'])\n",
    "    print('====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214ec2c-42d1-456f-a198-5db36c8041ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
